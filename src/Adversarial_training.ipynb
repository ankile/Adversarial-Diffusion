{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ankile/Adversarial-Diffusion/blob/main/src/Adverserial_training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "669EcStMGKut"
      },
      "source": [
        "# Adversarial training\n",
        "\n",
        "Code to train adversarially robust models as part of the diffusion as adversarial defense project.\n",
        "\n",
        "The following two cells must be run before restarting the runtime to ensure that the `tiatoolbox` package loads correctly.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bUBP8yEWbc4D"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install tiatoolbox    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PBN33YTukTtL"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!apt-get -y install libopenjp2-7-dev libopenjp2-tools openslide-tools"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "aWc9e1SGEjVM",
        "outputId": "f8d13589-adc2-4eaa-be11-8e97de49bd43"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Running on: cuda'"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from sklearn.metrics import accuracy_score\n",
        "from tiatoolbox.models.architecture import get_pretrained_model\n",
        "from torchvision.datasets import pcam\n",
        "from torchvision import transforms\n",
        "from tiatoolbox.models.dataset.classification import predefined_preproc_func\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "f\"Running on: {device}\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qNIGonmQ1ZLe"
      },
      "source": [
        "### Load Datasets\n",
        "\n",
        "The PCam dataset from TiaToolBox was used. A subset of the validation set was used for training, as it was smaller than the training set, and therefore did not take up precious memory.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P3ZsHs3FbRut"
      },
      "outputs": [],
      "source": [
        "# load preprocessing\n",
        "preprocess_pcam = predefined_preproc_func(\"pcam\")\n",
        "\n",
        "# load total datasets\n",
        "train_dataset = pcam.PCAM(\n",
        "    root=\"data\", split=\"val\", download=True, transform=preprocess_pcam.func\n",
        ")\n",
        "\n",
        "# load test data\n",
        "test_dataset = pcam.PCAM(\n",
        "    root=\"data\", split=\"test\", download=True, transform=preprocess_pcam.func\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HQg9J9i415Cp"
      },
      "source": [
        "### Adversarial Example Creator\n",
        "\n",
        "The following function generates adversarial examples from a given image, for a given model. This was used to create training examples during adversarial training, and in testing across all methods.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H_00unrGyZHP"
      },
      "outputs": [],
      "source": [
        "def create_adverserial(input_tensor, true, model, no_iter=5, lr=1e5):\n",
        "    epsilon = 2 / 255\n",
        "    # epsilon = 2/255/10\n",
        "    delta = torch.zeros_like(input_tensor, requires_grad=True)\n",
        "    opt = optim.Adam([delta], lr=lr)\n",
        "\n",
        "    for t in range(no_iter):\n",
        "        pred = model((input_tensor + delta).to(device).unsqueeze(0)).to(device)\n",
        "        loss = -nn.CrossEntropyLoss()(\n",
        "            pred.to(device), torch.LongTensor([true]).to(device)\n",
        "        )\n",
        "\n",
        "        opt.zero_grad()\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "        delta.data.clamp_(-epsilon, epsilon)\n",
        "    return input_tensor + delta"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aEJJJpAg2Kmt"
      },
      "source": [
        "### Adversarial Training & Test function\n",
        "\n",
        "**Adversarial Training:** Function that loops over training data, creating adversarial examples and updating model parameters.\n",
        "\n",
        "**Test**: Function that loops over test data, creating adversarial examples and measuring both standard and robust accuracy.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jzVSmK-10R4e"
      },
      "outputs": [],
      "source": [
        "def adverserial_training(net, trainloader, lr=1e-5, epoch_no=1):\n",
        "    print(f\"learning rate:{lr}\")\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(net.parameters(), lr=lr)\n",
        "\n",
        "    for epoch in range(epoch_no):  # loop over the dataset multiple times\n",
        "        running_loss = 0.0\n",
        "\n",
        "        for i, (inputs, labels) in tqdm(\n",
        "            enumerate(trainloader, 0), total=len(trainloader)\n",
        "        ):\n",
        "            # get the inputs; data is a list of [inputs, labels]\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            # change model status\n",
        "            net.eval()\n",
        "\n",
        "            # create adverserial example\n",
        "            inputs = create_adverserial(inputs.squeeze(0), labels, net).unsqueeze(0)\n",
        "\n",
        "            # change model status\n",
        "            net.train()\n",
        "\n",
        "            # zero the parameter gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # forward + backward + optimize\n",
        "            outputs = net(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "    print(\"Finished Training\")\n",
        "    return net\n",
        "\n",
        "\n",
        "def test(net, test_dataset, test_size=500):\n",
        "    # 1. Create Adverserial Examples\n",
        "    subset_test_dataset = torch.utils.data.Subset(\n",
        "        test_dataset, list(range(0, test_size))\n",
        "    )\n",
        "    testloader = torch.utils.data.DataLoader(\n",
        "        subset_test_dataset,\n",
        "        batch_size=1,\n",
        "    )\n",
        "\n",
        "    # change model status\n",
        "    net.eval()\n",
        "\n",
        "    correct_std = 0\n",
        "    total_std = 0\n",
        "    # create test_dataset & calculate standard accuracy\n",
        "    test_adverserial_set = []\n",
        "    for i, (inputs, labels) in tqdm(enumerate(testloader, 0), total=len(testloader)):\n",
        "        # get the inputs; data is a list of [inputs, labels]\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        outputs = net(inputs)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total_std += labels.size(0)\n",
        "        correct_std += (predicted == labels).sum().item()\n",
        "\n",
        "        # create adverserial example\n",
        "        adverserial = create_adverserial(inputs.squeeze(0), labels, net)\n",
        "        test_adverserial_set.append([adverserial, labels])\n",
        "\n",
        "    print(\n",
        "        f\"Standard accuracy of the network on the {test_size} test images: {100 * correct_std // total_std} %\"\n",
        "    )\n",
        "    std_accuracy = 100 * correct_std // total_std\n",
        "\n",
        "    # 2. Test Model\n",
        "    net.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    # since we're not training, we don't need to calculate the gradients for our outputs\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in test_adverserial_set:\n",
        "            # calculate outputs by running images through the network\n",
        "            outputs = net(inputs.unsqueeze(0))\n",
        "            # the class with the highest energy is what we choose as prediction\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    print(\n",
        "        f\"Adversarial Accuracy of the network on the {test_size} test images: {100 * correct // total} %\"\n",
        "    )\n",
        "    accuracy = 100 * correct // total\n",
        "\n",
        "    return accuracy, std_accuracy\n",
        "    # return std_accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EdkBklq-2usX"
      },
      "source": [
        "### Adversarial Training of 3 Different Classifiers\n",
        "\n",
        "In the following code, we load seven pre-trained models and perform adversarial training on each of them, from which we determined that GoogLeNet performed the best.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "wEiG642AAMJ6",
        "outputId": "29cfbbef-9a7f-480e-9d92-e9674a5835c1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using model: wide_resnet101_2\n",
            "Download from https://tiatoolbox.dcs.warwick.ac.uk/models/pc/wide_resnet101_2-pcam.pth\n",
            "Save to /root/.tiatoolbox/models/wide_resnet101_2-pcam.pth\n",
            "learning rate:1e-10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:31<00:00,  3.17it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Finished Training\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [04:02<00:00,  4.12it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Standard accuracy of the network on the 1000 test images: 51 %\n",
            "Adversarial Accuracy of the network on the 1000 test images: 51 %\n"
          ]
        }
      ],
      "source": [
        "models = [\n",
        "    \"resnet101\",\n",
        "    \"resnet50\",\n",
        "    \"googlenet\",\n",
        "    \"wide_resnet101_2\",\n",
        "    \"alexnet\",\n",
        "    \"densenet201\",\n",
        "    \"resnext101\",\n",
        "]\n",
        "\n",
        "for model_selection in models:\n",
        "    print(f\"Using model: {model_selection}\")\n",
        "    model = get_pretrained_model(pretrained_model=f\"{model_selection}-pcam\")\n",
        "    net = model[0].to(device)\n",
        "\n",
        "    # sample random training data\n",
        "    train_indices = np.random.choice(\n",
        "        np.arange(len(train_dataset)), size=1000, replace=False\n",
        "    )\n",
        "    # create data loader from sample subset\n",
        "    subset_train_dataset = torch.utils.data.Subset(train_dataset, train_indices)\n",
        "    trainloader = torch.utils.data.DataLoader(\n",
        "        subset_train_dataset,\n",
        "        batch_size=1,\n",
        "        shuffle=True,\n",
        "    )\n",
        "\n",
        "    # adverserial training\n",
        "    net = adverserial_training(net, trainloader, lr=1e-10)\n",
        "    accuracy, std_accuracy = test(net, test_dataset, test_size=1000)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kqhYGko7FThN"
      },
      "source": [
        "### Adversarial Training Using Varying Number of Training Examples\n",
        "\n",
        "Next we analyzed how the performance changed depending on the number of adversarial examples used during training.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rnRgHXct6Lwh"
      },
      "outputs": [],
      "source": [
        "# points to stop at\n",
        "i = [1, 10, 50, 100, 500, 1000]\n",
        "\n",
        "# load starting model\n",
        "model_selection = models[1]\n",
        "model = get_pretrained_model(pretrained_model=f\"{model_selection}-pcam\")\n",
        "net = model[0]\n",
        "net.to(\"cuda\")\n",
        "\n",
        "# accuracy scores\n",
        "acc_scores = []\n",
        "\n",
        "for j in range(len(i)):\n",
        "    if j == 0:\n",
        "        index_start = 0\n",
        "    else:\n",
        "        index_start = i[j - 1] + 1\n",
        "    index_end = i[j]\n",
        "\n",
        "    # select subset of data\n",
        "    subset_train_dataset = torch.utils.data.Subset(\n",
        "        train_dataset, list(range(index_start, index_end))\n",
        "    )\n",
        "    trainloader = torch.utils.data.DataLoader(\n",
        "        subset_train_dataset,\n",
        "        batch_size=1,\n",
        "    )\n",
        "\n",
        "    # adverserial training\n",
        "    net = adverserial_training(net, trainloader)\n",
        "\n",
        "    # test\n",
        "    accuracy = test(net, test_dataset, test_size=100)\n",
        "    acc_scores.append(accuracy)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
